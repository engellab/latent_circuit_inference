{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6dfcb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from copy import deepcopy\n",
    "from geoopt.optim import RiemannianAdam\n",
    "sys.path.append(\"./\")\n",
    "sys.path.append(\"../\")\n",
    "sys.path.append(\"../../\")\n",
    "import numpy as np\n",
    "import json\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from rnn_coach.src.RNN_torch import *\n",
    "from rnn_coach.src.DynamicSystemAnalyzer import *\n",
    "from rnn_coach.src.RNN_numpy import *\n",
    "from rnn_coach.src.Task import *\n",
    "from rnn_coach.src.DataSaver import *\n",
    "from src.utils import jsonify\n",
    "from latent_circuit_inference.src.LatentCircuit import *\n",
    "from latent_circuit_inference.src.LatentCircuitFitter import *\n",
    "from latent_circuit_inference.src.LCAnalyzer import *\n",
    "from latent_circuit_inference.src.utils import *\n",
    "from latent_circuit_inference.src.circuit_vizualization import *\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "import pickle\n",
    "import json\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from rnn_coach.src.utils import get_colormaps\n",
    "colors, cmp = get_colormaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "feb3f929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 650538\n"
     ]
    }
   ],
   "source": [
    "def mse_scoring(x, y):\n",
    "    return np.mean((x - y) ** 2)\n",
    "\n",
    "def R2(x, y):\n",
    "    return 1.0 - mse_scoring(x, y)/np.var(y)\n",
    "\n",
    "def plot_matrix(mat, vmin=None, vmax=None, show_numbers = False, figsize = (7,7)):\n",
    "    if vmin is None:\n",
    "        vmin = np.min(mat)\n",
    "    if vmax is None:\n",
    "        vmax = np.max(mat)    \n",
    "    fig, ax = plt.subplots(1, 1, figsize = figsize)\n",
    "    img = ax.imshow(mat, cmap=cmp, vmin = vmin, vmax = vmax)\n",
    "    if show_numbers:\n",
    "        for (i, j), z in np.ndenumerate(mat):\n",
    "            if np.abs(z) > 0.01:\n",
    "                ax.text(j, i, str(np.round(z, 2)), ha=\"center\", va=\"center\", color='k', fontsize=7)\n",
    "    ax.set_xticks(np.arange(mat.shape[1])[::2])\n",
    "    ax.set_yticks(np.arange(mat.shape[0])[::2])\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def permute_input_matrix(mat, order):\n",
    "    new_mat = np.empty_like(mat)\n",
    "    for i, r in enumerate(order):\n",
    "        new_mat[i, :] = mat[r, :]\n",
    "    return new_mat\n",
    "\n",
    "projects_folder = str(Path.home()) + \"/Documents/GitHub/\"\n",
    "RNN = '0.0018708_CDDM_tanh;tanh;N=100;lmbdo=0.3;lmbdr=0.5;lr=0.002;maxiter=3000'\n",
    "RNN_folder = RNN\n",
    "RNNs_path = os.path.join(projects_folder, \"rnn_coach\", \"data\", \"trained_RNNs\", \"CDDM_tanh\")\n",
    "RNN_score = float(RNN.split(\"_\")[0])\n",
    "RNN_path = os.path.join(RNNs_path, RNN)\n",
    "rnn_config = json.load(open(os.path.join(RNN_path, f\"{RNN_score}_config.json\"), \"rb+\"))\n",
    "rnn_data = json.load(open(os.path.join(RNN_path, f\"{RNN_score}_params_CDDM_tanh.json\"), \"rb+\"))\n",
    "train_config_file = f\"train_config_CDDM_relu.json\"\n",
    "\n",
    "activation_name = rnn_config[\"activation\"]\n",
    "RNN_N = rnn_config[\"N\"]\n",
    "n_steps = rnn_config[\"n_steps\"]\n",
    "task_params = rnn_config[\"task_params\"]\n",
    "activation_torch = lambda x: torch.maximum(x, torch.tensor(0))\n",
    "dt = rnn_config[\"dt\"]\n",
    "tau = rnn_config[\"tau\"]\n",
    "connectivity_density_rec = rnn_config[\"connectivity_density_rec\"]\n",
    "spectral_rad = rnn_config[\"sr\"]\n",
    "sigma_inp = 0.03\n",
    "sigma_rec = 0.03\n",
    "seed = np.random.randint(1000000)\n",
    "\n",
    "\n",
    "print(f\"seed: {seed}\")\n",
    "device = torch.device('cpu')\n",
    "rng = torch.Generator(device=torch.device(device))\n",
    "if not seed is None:\n",
    "    rng.manual_seed(seed)\n",
    "input_size = np.array(rnn_data[\"W_inp\"]).shape[1]\n",
    "output_size = np.array(rnn_data[\"W_out\"]).shape[0]\n",
    "mask = np.array(rnn_config[\"mask\"])\n",
    "\n",
    "tag = '8nodes'\n",
    "LCI_config_file = json.load(open(os.path.join(projects_folder, \"latent_circuit_inference\", \"data\", \"configs\", f\"LCI_config_{tag}.json\"), mode=\"r\", encoding='utf-8'))\n",
    "task_data = rnn_config[\"task_params\"]\n",
    "tmp = task_data[\"coherences\"][-1] * np.logspace(-(5 - 1), 0, 5, base=2)\n",
    "coherences = np.concatenate([-np.array(tmp[::-1]), np.array([0]), np.array(tmp)]).tolist()\n",
    "task_data[\"coherences\"] = deepcopy(coherences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b66a2939",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = rnn_data[\"dt\"]\n",
    "tau = rnn_data[\"tau\"]\n",
    "\n",
    "N = rnn_data[\"N\"]\n",
    "W_inp = np.array(rnn_data[\"W_inp\"])\n",
    "W_rec = np.array(rnn_data[\"W_rec\"])\n",
    "W_out = np.array(rnn_data[\"W_out\"])\n",
    "activation_numpy = lambda x: np.tanh(0, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada7ece3",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_params_ = deepcopy(task_params)\n",
    "task_params_[\"coherences\"] = np.array([-0.8, -0.5, -0.2, -0.1, 0, 0.1, 0.2, 0.5, 0.8])\n",
    "# task_params_[\"coherences\"] = np.array([-0.8, 0, 0.8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75aa383f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up torch RNN\n",
    "activation_numpy = lambda x: np.tanh(x)\n",
    "RNN = RNN_numpy(N=N,\n",
    "                dt=dt, tau=tau,\n",
    "                W_inp=W_inp,\n",
    "                W_rec=W_rec,\n",
    "                W_out=W_out,\n",
    "                activation=activation_numpy)\n",
    "task = TaskCDDM_tanh(n_steps=n_steps, n_inputs=input_size, n_outputs=output_size, task_params=task_params_)\n",
    "inputs, targets, conditions = task.get_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0abeb0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task:\n",
    "n_steps = task_data[\"n_steps\"]\n",
    "\n",
    "LCn = 9 #(10 clusters)\n",
    "N_PCs = 20 # PCAs\n",
    "inp_connectivity_mask = np.zeros((LCn, input_size))\n",
    "inp_connectivity_mask[:input_size, :input_size] = np.eye(input_size)\n",
    "\n",
    "w_inp_init = deepcopy(inp_connectivity_mask)\n",
    "w_rec_init = np.random.randn(LCn, LCn)\n",
    "rec_connectivity_mask = np.ones_like(w_rec_init)\n",
    "w_out_init = np.random.randn(output_size, LCn)\n",
    "out_connectivity_mask = np.ones_like(w_out_init)\n",
    "\n",
    "# Fitter:\n",
    "lambda_w = 0.5\n",
    "max_iter = 1000\n",
    "tol = LCI_config_file[\"tol\"]\n",
    "lr = 0.01\n",
    "actvation_name = LCI_config_file[\"activation\"]\n",
    "Qinitialization = LCI_config_file[\"Qinitialization\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23492d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for RNN!\n"
     ]
    }
   ],
   "source": [
    "# # creating instances:\n",
    "activation_torch = lambda x: torch.tanh(x)\n",
    "rnn_torch = RNN_torch(N=RNN_N, dt=dt, tau=tau, input_size=input_size, output_size=output_size,\n",
    "                      activation=activation_torch, random_generator=rng, device=device,\n",
    "                      sigma_rec=sigma_rec, sigma_inp=sigma_inp)\n",
    "RNN_params = {\"W_inp\": np.array(rnn_data[\"W_inp\"]),\n",
    "              \"W_rec\": np.array(rnn_data[\"W_rec\"]),\n",
    "              \"W_out\": np.array(rnn_data[\"W_out\"]),\n",
    "              \"b_rec\": np.array(rnn_data[\"bias_rec\"]),\n",
    "              \"y_init\": np.zeros(RNN_N)}\n",
    "rnn_torch.set_params(RNN_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f6127a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = TaskCDDM_tanh(n_steps=n_steps, n_inputs=input_size, n_outputs=output_size, task_params=task_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f9ee592c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu for Latent Circuit!\n"
     ]
    }
   ],
   "source": [
    "lc = LatentCircuit(N=LCn,\n",
    "                   num_inputs=input_size,\n",
    "                   num_outputs=output_size,\n",
    "                   W_inp=torch.Tensor(w_inp_init).to(device),\n",
    "                   W_out=torch.Tensor(w_out_init).to(device),\n",
    "                   inp_connectivity_mask=torch.Tensor(inp_connectivity_mask).to(device),\n",
    "                   rec_connectivity_mask=torch.Tensor(rec_connectivity_mask).to(device),\n",
    "                   out_connectivity_mask=torch.Tensor(out_connectivity_mask).to(device),\n",
    "                   dale_mask = None,\n",
    "                   activation=activation_torch,\n",
    "                   sigma_rec=sigma_rec,\n",
    "                   sigma_inp=sigma_inp,\n",
    "                   device=device,\n",
    "                   random_generator=rng)\n",
    "\n",
    "# lc.recurrent_layer.weight.data = deepcopy(torch.from_numpy(w_rec_init.astype(\"float32\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d24e37b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "setting projection of RNN traces on the lower subspace\n"
     ]
    }
   ],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "fitter = LatentCircuitFitter(LatentCircuit=lc,\n",
    "                             RNN=rnn_torch,\n",
    "                             Task=task,\n",
    "                             N_PCs = N_PCs,\n",
    "                             encoding = True,\n",
    "                             max_iter=max_iter,\n",
    "                             tol=tol, lr = lr,\n",
    "                             criterion=criterion,\n",
    "                             lambda_w=lambda_w,\n",
    "                             Qinitialization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "23c89a43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear(in_features=6, out_features=9, bias=False)\n"
     ]
    }
   ],
   "source": [
    "print(fitter.LatentCircuit.input_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7366f6f6",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (4) must match the size of tensor b (6) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lc_inferred, train_losses, val_losses, net_params \u001b[38;5;241m=\u001b[39m \u001b[43mfitter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/latent_circuit_inference/src/LatentCircuitFitter.py:199\u001b[0m, in \u001b[0;36mLatentCircuitFitter.run_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    196\u001b[0m     y, predicted_output_rnn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mRNN(input_batch)\n\u001b[1;32m    198\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28miter\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_iter):\n\u001b[0;32m--> 199\u001b[0m     train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_output_rnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdetach\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;66;03m# validation\u001b[39;00m\n\u001b[1;32m    201\u001b[0m     val_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39meval_step(input_val, y, predicted_output_rnn)\n",
      "File \u001b[0;32m~/Documents/GitHub/latent_circuit_inference/src/LatentCircuitFitter.py:130\u001b[0m, in \u001b[0;36mLatentCircuitFitter.train_step\u001b[0;34m(self, input, y, predicted_output_RNN)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, y, predicted_output_RNN):\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLatentCircuit\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m--> 130\u001b[0m     x, predicted_output_lc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLatentCircuit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(predicted_output_lc, predicted_output_RNN) \u001b[38;5;241m/\u001b[39m torch\u001b[38;5;241m.\u001b[39mvar(predicted_output_RNN, unbiased\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    133\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_w \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLatentCircuit\u001b[38;5;241m.\u001b[39mrecurrent_layer\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    134\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_w \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLatentCircuit\u001b[38;5;241m.\u001b[39minput_layer\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m    135\u001b[0m            \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlambda_w \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLatentCircuit\u001b[38;5;241m.\u001b[39moutput_layer\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding:\n",
      "File \u001b[0;32m~/miniconda3/envs/gpu_env/lib/python3.10/site-packages/torch/nn/modules/module.py:1488\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1486\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1487\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1488\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1490\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Documents/GitHub/latent_circuit_inference/src/LatentCircuit.py:94\u001b[0m, in \u001b[0;36mLatentCircuit.forward\u001b[0;34m(self, u, w_noise)\u001b[0m\n\u001b[1;32m     88\u001b[0m inp_noise \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mswapaxes(inp_noise, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(T_steps \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m     90\u001b[0m     state_new \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha) \u001b[38;5;241m*\u001b[39m states[:, i, :] \u001b[38;5;241m+\u001b[39m \\\n\u001b[1;32m     91\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m (\n\u001b[1;32m     92\u001b[0m                     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation(\n\u001b[1;32m     93\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurrent_layer(states[:, i, :]) \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m---> 94\u001b[0m                         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layer(\u001b[43mu\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minp_noise\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m)) \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m     95\u001b[0m                     rec_noise[:, i, :]\n\u001b[1;32m     96\u001b[0m                 )\n\u001b[1;32m     97\u001b[0m     states \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((states, state_new\u001b[38;5;241m.\u001b[39munsqueeze_(\u001b[38;5;241m1\u001b[39m)), \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     98\u001b[0m outputs \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mswapaxes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_layer(states), \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (6) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "lc_inferred, train_losses, val_losses, net_params = fitter.run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d79a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
